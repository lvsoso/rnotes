<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>GPT | rnotes</title>
    <meta name="generator" content="VuePress 1.8.0">
    <link rel="icon" href="https://cdn.staticaly.com/gh//tu/main/img/image_20220720_132133.ico">
    <script language="javascript" type="text/javascript" src="/rnotes/js/pgmanor-self.js"></script>
    <meta name="description" content="vdoing博客主题模板">
    <meta name="keywords" content="二丫讲梵,golang,vue,go-web,go-admin,go-ldap-admin">
    <meta name="theme-color" content="#11a8cd">
    <meta name="referrer" content="no-referrer-when-downgrade">
    
    <link rel="preload" href="/rnotes/assets/css/0.styles.b6f582e0.css" as="style"><link rel="preload" href="/rnotes/assets/js/app.bf8f4476.js" as="script"><link rel="preload" href="/rnotes/assets/js/2.9060e935.js" as="script"><link rel="preload" href="/rnotes/assets/js/28.7ae27e4d.js" as="script"><link rel="prefetch" href="/rnotes/assets/js/10.ccb2e8ec.js"><link rel="prefetch" href="/rnotes/assets/js/11.f5243cce.js"><link rel="prefetch" href="/rnotes/assets/js/12.eb47a4f5.js"><link rel="prefetch" href="/rnotes/assets/js/13.c43dd985.js"><link rel="prefetch" href="/rnotes/assets/js/14.b78e2bc5.js"><link rel="prefetch" href="/rnotes/assets/js/15.e578bcdb.js"><link rel="prefetch" href="/rnotes/assets/js/16.fbcbe513.js"><link rel="prefetch" href="/rnotes/assets/js/17.daa9d0c3.js"><link rel="prefetch" href="/rnotes/assets/js/18.81db6855.js"><link rel="prefetch" href="/rnotes/assets/js/19.7c20a05b.js"><link rel="prefetch" href="/rnotes/assets/js/20.b2495a53.js"><link rel="prefetch" href="/rnotes/assets/js/21.96661804.js"><link rel="prefetch" href="/rnotes/assets/js/22.04880741.js"><link rel="prefetch" href="/rnotes/assets/js/23.2ce4a714.js"><link rel="prefetch" href="/rnotes/assets/js/24.36dd859e.js"><link rel="prefetch" href="/rnotes/assets/js/25.bd6b2fcc.js"><link rel="prefetch" href="/rnotes/assets/js/26.53e15e6f.js"><link rel="prefetch" href="/rnotes/assets/js/27.9335743c.js"><link rel="prefetch" href="/rnotes/assets/js/29.800ff01a.js"><link rel="prefetch" href="/rnotes/assets/js/3.bdac8f6d.js"><link rel="prefetch" href="/rnotes/assets/js/30.f94f40d0.js"><link rel="prefetch" href="/rnotes/assets/js/31.7a34d1dc.js"><link rel="prefetch" href="/rnotes/assets/js/32.5efcf0ef.js"><link rel="prefetch" href="/rnotes/assets/js/33.b3cb9c50.js"><link rel="prefetch" href="/rnotes/assets/js/34.580774d8.js"><link rel="prefetch" href="/rnotes/assets/js/35.9d924086.js"><link rel="prefetch" href="/rnotes/assets/js/36.f8d5b30b.js"><link rel="prefetch" href="/rnotes/assets/js/37.f121ba8d.js"><link rel="prefetch" href="/rnotes/assets/js/38.d9871c2d.js"><link rel="prefetch" href="/rnotes/assets/js/39.eaafb4df.js"><link rel="prefetch" href="/rnotes/assets/js/4.4e259541.js"><link rel="prefetch" href="/rnotes/assets/js/40.bf90314f.js"><link rel="prefetch" href="/rnotes/assets/js/41.0118f368.js"><link rel="prefetch" href="/rnotes/assets/js/42.5aba3546.js"><link rel="prefetch" href="/rnotes/assets/js/43.3e980207.js"><link rel="prefetch" href="/rnotes/assets/js/44.580a4a5b.js"><link rel="prefetch" href="/rnotes/assets/js/45.bb355ea0.js"><link rel="prefetch" href="/rnotes/assets/js/46.b660bbaa.js"><link rel="prefetch" href="/rnotes/assets/js/47.5cd1805f.js"><link rel="prefetch" href="/rnotes/assets/js/48.880dadae.js"><link rel="prefetch" href="/rnotes/assets/js/49.fa65cb36.js"><link rel="prefetch" href="/rnotes/assets/js/5.2dbab697.js"><link rel="prefetch" href="/rnotes/assets/js/50.aa267736.js"><link rel="prefetch" href="/rnotes/assets/js/51.41ad17b8.js"><link rel="prefetch" href="/rnotes/assets/js/52.aceb364b.js"><link rel="prefetch" href="/rnotes/assets/js/53.770b50ac.js"><link rel="prefetch" href="/rnotes/assets/js/54.b7be0559.js"><link rel="prefetch" href="/rnotes/assets/js/6.5d3e4707.js"><link rel="prefetch" href="/rnotes/assets/js/7.b0fd77b8.js"><link rel="prefetch" href="/rnotes/assets/js/8.652d2af3.js"><link rel="prefetch" href="/rnotes/assets/js/9.4ea9191d.js">
    <link rel="stylesheet" href="/rnotes/assets/css/0.styles.b6f582e0.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/rnotes/" class="home-link router-link-active"><!----> <span class="site-name">rnotes</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <!----></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><!----> <!---->  <ul class="sidebar-links"><li><a href="/rnotes/pages/e37611/" aria-current="page" class="active sidebar-link">GPT</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/rnotes/pages/72ce5b/" class="sidebar-link">quant</a></li><li><a href="/rnotes/pages/b15368/" class="sidebar-link">deploy</a></li><li><a href="/rnotes/pages/07967a/" class="sidebar-link">nn</a></li><li><a href="/rnotes/pages/5274ba/" class="sidebar-link">tool</a></li><li><a href="/rnotes/pages/fc8971/" class="sidebar-link">llm</a></li><li><a href="/rnotes/pages/6b5ce6/" class="sidebar-link">ml-llm-ops</a></li><li><a href="/rnotes/pages/5a579f/" class="sidebar-link">llm-app</a></li><li><a href="/rnotes/pages/e486ab/" class="sidebar-link">llm-mcp</a></li><li><a href="/rnotes/pages/597260/" class="sidebar-link">llm-agent</a></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/rnotes/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/rnotes/deep-learning/#dl" data-v-06225672>dl</a></li></ul> <div class="info" data-v-06225672><!----> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2025-05-11</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABGpJREFUSA3tVVtoXFUU3fvOI53UlmCaKIFmwEhsE7QK0ipFEdHEKpXaZGrp15SINsXUWvBDpBgQRKi0+KKoFeJHfZA+ED9KKoIU2gYD9UejTW4rVIzm0VSTziPzuNu1z507dibTTjL4U/DAzLn3nL3X2o91ziX6f9wMFdh6Jvbm9nNSV0msViVO6tN1Rm7NMu2OpeJ9lWBUTDxrJbYTS0hInuwciu9eLHlFxCLCZEk3MegsJmZ5K/JD6t7FkFdEvGUo1g7qJoG3MHImqRIn8/nzY1K9UPKKiJmtnUqHVE3Gbuay6vJE/N2FEmuxFjW2nUuE0yQXRRxLiTUAzs36zhZvOXJPdX850EVnnLZkB8prodQoM5JGj7Xk2mvC7JB8tG04Ef5PiXtG0UtxupRQSfTnBoCy554x18yJHI6I+G5Eru4LHmPJZEQsrvPUbMiA8G/WgMK7w7I+ez7++o2ANfbrjvaOl1tFMs+htG3IrZH9/hDX1Pr8Tc0UvH8tcX29KzAgIGcEkINyW5BF9x891hw6VYqgJHEk0huccS7vh3C6gTiODL+26huuBtbct8eZnqLML8PkxGYpuPZBqtqwkSjgc4mB5gbgig5i+y0UDK35LMxXisn9xQtK+nd26gTIHsHe/oblK/b29fUmN/8Y+9jAQrnBp56m1LcDlDp9irKTExSKduXJVWSqdBMA08pEJnEIOB3FPPMybu/oeV8zFeYN3xx576Q6RH+VmplE4ncQV5v+5rzSoyOU7PuEAg8g803PwBJ0CExno/jcMbN8tONYeOmHiuUNryvm3fRUy4tMPVLdAGkUhNWuggGrJcXPv+ouCjz0MKUHz1J2/E8IC9nqTabcxgaBYM0hPhD5Y65FsbxRQKxCQrDjDctW7PUM3HuZunFyifSAqEfuzCp48Il24luWUWZoyJCaPR82jE0+kFA643wRFVni4RYSq3ohJO2pZ7B5dO4xkDWbEpossJPLSrPjYID8rS2UHTlvyNxqIGsg674XJJ7vnh5L7PNwC4hh2sjCI96mzszOTpxLF0T7l88Yz7lAuK6OnL8gXLOnTvpzSb22YG8W7us3jSebFHeeqnXRG1vt+MoUM84LQIBmMsCTAcOauTh0T0l0neQK7m2bLMt2mGxU3HYssS0J2cdv5wljlPsrIuZLAG/2DOZIXgCYT8uMGZN+e2kSirfxZOPCsC0f24nTZzspnVn9VePS1Z5vubmAGGXG8ZFno9Hel0yfA5ZPhF7Dh972BQJ2qCpgH67lmWtBYbvk6sz02wjky2vXyz0XErP/kFB619js1BtwfOV4OPRqOQBjy3Qbk18vigUPPSD5ceHnwck7W9bhAqZdd7SuG7w4/P2F/GaJh8c7e9qgow+Q7cGBo+98WsLkuktFqiZabtXuQTu/Y5ETbR0v7tNSFnvrmu6pjdoan2KjMu8q/Hmj1EfCO2ZGfEIbIXKUlw8qaX9/b2oeSJmFksSeT/Fn0V3nSypChh4Gjh74ybO9aeZ/AN2dwciu2/MhAAAAAElFTkSuQmCC">GPT<!----></h1> <!----> <div class="theme-vdoing-content content__default"><h3 id="推理过程"><a href="#推理过程" class="header-anchor">#</a> 推理过程</h3> <p>1.输入处理</p> <ul><li>分词：拆分token</li> <li>向量嵌入：查找对应的向量。token本身有对应的向量 N<em>12288，“位置（输入中的位置）”也有其对应的向量 N</em>12288</li> <li>词向量+位置向量：两个矩阵相加 产生一个输出矩阵</li></ul> <p>2.编码器处理</p> <p>96 层解码器（自注意力子层+前馈神经网络子层）</p> <p><strong>自注意力子层</strong></p> <p>解码器多头自回归自注意力机制；</p> <p>注意力：输入序列与输出序列之间的关系、依赖；
自注意力：没有严格的输出序列，关注输入序列；</p> <p>自回归/单向/因果：自注意力机制</p> <p>多头：分成多头，分别取不同的语义表示</p> <p>每个自注意力头的q问题、k索引、v答案矩阵：12288 * 128</p> <p>自注意力头计算： n * 12288 dot 12288 * 128  = n * 128</p> <p>qk转置/点积计算： Q(n * 128) dot K(128 * n) = n*n 权重矩阵</p> <p>缩放：除以sqrt(12288)</p> <p>掩码矩阵相乘： 下三角矩阵 1\</p> <p>softmax：</p> <p>乘以 V ：n * n dot n * 128 = n * 128</p> <p>多头向量(96 份输出)拼接：n * 128 * 96 = n * 12288</p> <p>全连接线性层：n * 12288 * 12288 * 12288 = n * 12288</p> <p>激活函数：非线性化、GRLU、RELU</p> <p>残差链接：原始输入+当前输出</p> <p>归一化层：均值为0，标准差为1</p> <p><strong>前馈神经网络子层</strong></p> <p>全连接扩张线性层： n * 12288 * (12288 * 4 * 12288) 扩张4倍</p> <p>激活函数：非线性</p> <p>全连接收缩线性层： ？ * 4 * 12288 * 12288 = n * 12288</p> <p>残差连接：</p> <p>归一化层：</p> <ol start="3"><li>处理输出</li></ol> <p>线性层：n * 12288 * (12288 * 50257) = n * 50257</p> <p>softmax：</p> <p>采样策略处理：确定下一个字</p> <p>迭代处理：</p> <h3 id="参数"><a href="#参数" class="header-anchor">#</a> 参数</h3> <p>输入词处理：
词向量参数矩阵 50257 * 122288
位置向量参数矩阵 2048 * 12288</p> <p>自注意力矩阵：( 12288 * 128 + 128 )* 3 * 96 + 12288*12288 + 12288
前馈神经网络子层： (12288 * 12288 * 4 + 12288 )+ （4 * 12288 * 12288 + 12288）</p> <p>解码器层（自注意力矩阵+前馈神经网络）* 96</p> <p>输出： 12288 * 50257 + 50257</p> <h3 id="训练"><a href="#训练" class="header-anchor">#</a> 训练</h3> <ul><li>初始化参数为随机值</li> <li>计算输出与真实数据的差距（损失和梯度）</li> <li>根据损失逐步调整权重参数</li></ul> <p>真实数据使用 one-hot编码矩阵</p> <p>交叉熵损失：预测结果取对数-与目标矩阵逐步位置相乘-求和-取反-除序列长度-训练集求和取平均-平均损失值</p> <h4 id="梯度计算"><a href="#梯度计算" class="header-anchor">#</a> 梯度计算</h4> <p>起始梯度：参数调整反向传播的起点，可以用目标矩阵减去预测结果矩阵</p> <p>梯度反向传播：链式法则</p> <p>参数矩阵梯度：输入矩阵转置乘输出矩阵梯度</p> <p>偏置向量梯度：等于逐列求和输出矩阵梯度</p> <p>输入矩阵梯度：等于输出矩阵梯度乘参数矩阵的梯度</p> <h4 id="学习率"><a href="#学习率" class="header-anchor">#</a> 学习率</h4> <ul><li>Adam： 计算均值和方差，动态调整学习率</li> <li>随机梯度下降</li> <li>小批量梯度下降</li></ul> <p>GPT 使用 Adam, 初始值比较小</p> <p>新的参数矩阵：参数矩阵-梯度矩阵 * 学习率
偏置向量：偏置向量-梯度向量 * 学习率</p> <h4 id="gpt-训练集"><a href="#gpt-训练集" class="header-anchor">#</a> GPT 训练集</h4> <ul><li>训练序列：2048 token;</li> <li>训练批次：多个训练序列，3.2M tokens;</li></ul> <p>每一个训练批次中，每一个输入序列都会计算一遍梯度，最后进行求和取平均得到平均梯度值，最后进行统一的参数调整；</p> <h3 id="微调"><a href="#微调" class="header-anchor">#</a> 微调</h3> <p>分类：无监督、自监督、半监督、监督、强化、迁移、联邦
标签：模型预测的目标变量，标注数据
fine tuning：有目的性的调整（参数、作用位置、影响）</p> <p>FT分类：</p> <ul><li>SFT：少量标签、会使用标签数据走训练、会走反向传播更新参数</li> <li>Prompt：提示词微调，对输入序列嵌入额外的token，可能更新参数？不一定走反向传播？</li> <li>Prefix：前缀微调，嵌入自有的向量/虚的token？，会参与训练，会修改虚token部分涉及的参数</li> <li>LORA：低秩矩阵适应微调，用一个低秩矩阵叠加进参数矩阵</li> <li>AT：adapter tuning，插件微调，插入小网络/矩阵，不影响原有参数</li> <li>RLHF：基于人类反馈的强化学习，建立奖励模型、引导，参与正向传播和反向传播</li></ul> <p>chatGPT: 300B token 迭代一次, RLHF(SFT,RM,PPO)</p> <h3 id="空间占用和算力"><a href="#空间占用和算力" class="header-anchor">#</a> 空间占用和算力</h3> <p>模型空间占用：
175000000000 * 16 / 8 / 1024 / 1024 / 1024 / 1024 ～ 326.36G</p> <p>3.14* 10 ^ 23 FLOPS
300B Token</p> <h3 id="门槛"><a href="#门槛" class="header-anchor">#</a> 门槛：</h3> <ol><li>参数</li></ol> <ul><li>词汇表</li> <li>词向量宽度/隐藏层宽度</li> <li>解码器层数</li> <li>自注意力头数</li> <li>参数精度</li></ul> <ol start="2"><li>算力</li></ol> <ul><li>芯片</li> <li>加速卡</li> <li>服务器</li> <li>网络</li> <li>环境</li></ul> <ol start="3"><li>训练数据</li></ol> <ul><li>原始数据</li> <li>总Token数</li> <li>训练数据量</li></ul> <h3 id="与大脑对比"><a href="#与大脑对比" class="header-anchor">#</a> 与大脑对比</h3> <ul><li>参数数量：神经元连接数</li> <li>权重：强弱</li> <li>规模：人脑&gt;&gt;大模型</li> <li>过程：人脑突触重塑，不会反向传播，大模型推训分离</li> <li>功耗：人脑&lt;&lt;大模型</li> <li>结构：相差大</li></ul> <h3 id="编码器对比解码器"><a href="#编码器对比解码器" class="header-anchor">#</a> 编码器对比解码器</h3> <ul><li>编码器的输出根据任务而定，解码器输出就是下一个字的概率矩阵；</li> <li>编码器通过MLM（随机掩码学习）NSP（下一句预测）等方式训练，解码器训练下一个字的预测和生成；</li> <li>编码器的训练方法与推理场景不完全匹配、导致参数不合适；</li> <li>编码器吸收多，输出少；</li> <li>解码器更基本；</li> <li>大参数、大算力、大数据支持；</li></ul> <h3 id="自注意力溯源"><a href="#自注意力溯源" class="header-anchor">#</a> 自注意力溯源</h3> <ul><li>神经网络
<ul><li>深度神经网络
<ul><li>CNN（卷积神经网络）</li> <li>RNN（循环神经网络）
<ul><li>LSTM、CRU</li> <li>StoS 序列到序列模型
<ul><li>编码器+解码器</li></ul></li></ul></li> <li>注意力机制
<ul><li>Transformer
<ul><li>纯编码器（双向自注意力）</li> <li>纯解码器（单向自注意力）</li></ul></li></ul></li></ul></li></ul></li></ul> <h3 id="大模型的可解释性"><a href="#大模型的可解释性" class="header-anchor">#</a> 大模型的可解释性？</h3> <h4 id="人类思考的三种模式"><a href="#人类思考的三种模式" class="header-anchor">#</a> 人类思考的三种模式</h4> <ul><li>逻辑思考/推理
<ul><li>演绎</li> <li>归纳</li></ul></li> <li>概率/统计</li> <li>相关</li> <li>直觉</li></ul> <h4 id="人工智能的两种范式"><a href="#人工智能的两种范式" class="header-anchor">#</a> 人工智能的两种范式</h4> <ul><li>符号主义？（形式逻辑）
<ul><li>预先设定的规则</li> <li>确定的、可解释的</li></ul></li> <li>连接主义？（神经网络）
<ul><li>自主学习到的参数（规则、逻辑）</li> <li>随机的、不可解释的</li></ul></li></ul> <h4 id="大模型的随机性"><a href="#大模型的随机性" class="header-anchor">#</a> 大模型的随机性</h4> <ul><li>推理
<ul><li>输出层（随机确定下一个token）
<ul><li><blockquote><p>好处：多样性、鲁棒性、有助于创意式生成</p></blockquote></li> <li><blockquote><p>坏处：没有 确定性/准确性、幂等性、可管理性，不利于创意式生成</p></blockquote></li></ul></li></ul></li> <li>训练
<ul><li>参数随机初始化</li> <li>随机打乱训练数据/随机梯度下降</li> <li>Dropout（随机关闭神经元）</li></ul></li></ul> <h4 id="大模型的参数不可解读性"><a href="#大模型的参数不可解读性" class="header-anchor">#</a> 大模型的参数不可解读性</h4> <ul><li>结构无区别</li> <li>随机初始化</li> <li>数据量大（参数）</li> <li>无法参照现有人类知识体系解读</li></ul> <p>好处：智能？</p> <p>坏处：难以管理、压缩、裁剪、定向加强/减弱</p> <h3 id="未来"><a href="#未来" class="header-anchor">#</a> 未来</h3> <ul><li>插件
<ul><li>计算</li> <li>搜索</li> <li>代码</li></ul></li> <li>多模态</li> <li>参数规模</li> <li>多模型
<ul><li>MoE</li></ul></li> <li>推训一体（长期记忆）</li> <li>分布式</li> <li>个性化</li></ul></div></div> <!----> <div class="page-edit"><!----> <!----> <div class="last-updated"><span class="prefix">Last Updated:</span> <span class="time">2025/05/11, 13:05:09</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><!----> <a href="/rnotes/pages/72ce5b/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">quant</div></a></div> <div class="page-nav"><p class="inner"><!----> <span class="next"><a href="/rnotes/pages/72ce5b/">quant</a>→
      </span></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/rnotes/archives/" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/rnotes/pages/d54158/"><div>
            git
            <!----></div></a> <span class="date">05-11</span></dt></dl><dl><dd>02</dd> <dt><a href="/rnotes/pages/4b59a5/"><div>
            lib
            <!----></div></a> <span class="date">05-11</span></dt></dl><dl><dd>03</dd> <dt><a href="/rnotes/pages/b8590f/"><div>
            lfs
            <!----></div></a> <span class="date">05-11</span></dt></dl> <dl><dd></dd> <dt><a href="/rnotes/archives/" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><!----> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> <!----></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <!----></div><div class="global-ui"><!----></div></div>
    <script src="/rnotes/assets/js/app.bf8f4476.js" defer></script><script src="/rnotes/assets/js/2.9060e935.js" defer></script><script src="/rnotes/assets/js/28.7ae27e4d.js" defer></script>
  </body>
</html>
