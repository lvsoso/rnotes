### LLM应用

#### 基本概念
- chat
    - 多为HTTP接口形式提供对话能力
    - 可以是流式也可以是一次性的
- role
    - system: 系统设定
    - user: 用户本身
    - assistant: 模型
    - function: 函数
- prompt
    - 在发送对话中设置system的值，作为提问的背景设定甚至进行一些进一步的处理？
    - 所有的大模型都支持吗？
- 计费
    - 输入
        - prompt
        - 用户提问
    - 输出
        - 回答

- instruct 模型
    - 更好的遵循提示词指令

- function calling
    - 将一系列函数的名称和参数传给LLM，LLM根据用户输入进行自然语言解析，决定是否调用函数和提取所需参数
    - 谁调用函数？
        - 模型提供商？
        - 用户自定义函数？
        - 插件？
    - 模型的作用主要是函数的识别
        - 可以用prompt 来提示返回携带特定函数调用，实现函数识别的功能

- 多模态
    - 支持多种类型的输入
    - 目前主要是图片
        - 图片URL
        - 图片Base64

- RAG
    - LLM支持的上下文是有限的
        - 放更多的信息（密度）
        - 放更相关的信息（关联性） 
    - embedding
        - 将文本转换为向量
            - 向量的维度是固定的
        - 将一段长文本分成多个chunk，并对每个chunk进行embedding，保存到向量库
            - 向量库的维度是可变的
            - 向量库可以是内存库，也可以是文件库
    - RAG模型
        - 将向量库中的向量进行搜索，得到相关的文本
        - 加入到对话的中

- 微调
    - 直接用业务数据对底座模型进行微调
    - 相对RAG更全面的了解业务数据，回答相对准确
    - 不需要prompt方式放入更多数据
    - 不太灵活，不可控，成本高
    - 大模型提供商有对应的微调接口




#### 应用
- 对话
    - 文本生成
    - 文本分析
    - 文本翻译
    - 文本摘要
- 代码
    - 代码生成
    - 代码分析
    - 代码问答

