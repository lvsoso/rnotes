### 推理过程

1.输入处理

- 分词：拆分token
- 向量嵌入：查找对应的向量。token本身有对应的向量 N*12288，“位置（输入中的位置）”也有其对应的向量 N*12288
- 词向量+位置向量：两个矩阵相加 产生一个输出矩阵


2.编码器处理

96 层解码器（自注意力子层+前馈神经网络子层）


**自注意力子层**

解码器多头自回归自注意力机制；

注意力：输入序列与输出序列之间的关系、依赖；
自注意力：没有严格的输出序列，关注输入序列；

自回归/单向/因果：自注意力机制

多头：分成多头，分别取不同的语义表示

每个自注意力头的q问题、k索引、v答案矩阵：12288 * 128

自注意力头计算： n * 12288 dot 12288 * 128  = n * 128

qk转置/点积计算： Q(n * 128) dot K(128 * n) = n*n 权重矩阵

缩放：除以sqrt(12288)

掩码矩阵相乘： 下三角矩阵 1\

softmax：

乘以 V ：n * n dot n * 128 = n * 128

多头向量(96 份输出)拼接：n * 128 * 96 = n * 12288

全连接线性层：n * 12288 * 12288 * 12288 = n * 12288

激活函数：非线性化、GRLU、RELU

残差链接：原始输入+当前输出

归一化层：均值为0，标准差为1


**前馈神经网络子层**

全连接扩张线性层： n * 12288 * (12288 * 4 * 12288) 扩张4倍

激活函数：非线性

全连接收缩线性层： ？ * 4 * 12288 * 12288 = n * 12288

残差连接：

归一化层：


3. 处理输出

线性层：n * 12288 * (12288 * 50257) = n * 50257

softmax：

采样策略处理：确定下一个字

迭代处理：

### 参数

输入词处理：
词向量参数矩阵 50257 * 122288 
位置向量参数矩阵 2048 * 12288

自注意力矩阵：( 12288 * 128 + 128 )* 3 * 96 + 12288*12288 + 12288
前馈神经网络子层： (12288 * 12288 * 4 + 12288 )+ （4 * 12288 * 12288 + 12288）


解码器层（自注意力矩阵+前馈神经网络）* 96 

输出： 12288 * 50257 + 50257

### 训练
- 初始化参数为随机值
- 计算输出与真实数据的差距（损失和梯度）
- 根据损失逐步调整权重参数


真实数据使用 one-hot编码矩阵

交叉熵损失：预测结果取对数-与目标矩阵逐步位置相乘-求和-取反-除序列长度-训练集求和取平均-平均损失值

#### 梯度计算

起始梯度：参数调整反向传播的起点，可以用目标矩阵减去预测结果矩阵

梯度反向传播：链式法则

参数矩阵梯度：输入矩阵转置乘输出矩阵梯度

偏置向量梯度：等于逐列求和输出矩阵梯度

输入矩阵梯度：等于输出矩阵梯度乘参数矩阵的梯度

#### 学习率

- Adam： 计算均值和方差，动态调整学习率
- 随机梯度下降
- 小批量梯度下降


GPT 使用 Adam, 初始值比较小


新的参数矩阵：参数矩阵-梯度矩阵 * 学习率
偏置向量：偏置向量-梯度向量 * 学习率




#### GPT 训练集

- 训练序列：2048 token;
- 训练批次：多个训练序列，3.2M tokens;

每一个训练批次中，每一个输入序列都会计算一遍梯度，最后进行求和取平均得到平均梯度值，最后进行统一的参数调整；


### 微调

分类：无监督、自监督、半监督、监督、强化、迁移、联邦
标签：模型预测的目标变量，标注数据
fine tuning：有目的性的调整（参数、作用位置、影响）

FT分类：
- SFT：少量标签、会使用标签数据走训练、会走反向传播更新参数
- Prompt：提示词微调，对输入序列嵌入额外的token，可能更新参数？不一定走反向传播？
- Prefix：前缀微调，嵌入自有的向量/虚的token？，会参与训练，会修改虚token部分涉及的参数
- LORA：低秩矩阵适应微调，用一个低秩矩阵叠加进参数矩阵
- AT：adapter tuning，插件微调，插入小网络/矩阵，不影响原有参数
- RLHF：基于人类反馈的强化学习，建立奖励模型、引导，参与正向传播和反向传播


chatGPT: 300B token 迭代一次, RLHF(SFT,RM,PPO)

### 空间占用和算力

模型空间占用：
175000000000 * 16 / 8 / 1024 / 1024 / 1024 / 1024 ～ 326.36G

3.14* 10 ^ 23 FLOPS
300B Token


### 门槛：

1. 参数
- 词汇表
- 词向量宽度/隐藏层宽度
- 解码器层数
- 自注意力头数
- 参数精度

2. 算力
- 芯片
- 加速卡
- 服务器
- 网络
- 环境

3. 训练数据
- 原始数据
- 总Token数
- 训练数据量


### 与大脑对比

- 参数数量：神经元连接数
- 权重：强弱
- 规模：人脑>>大模型
- 过程：人脑突触重塑，不会反向传播，大模型推训分离
- 功耗：人脑<<大模型
- 结构：相差大


### 编码器对比解码器

- 编码器的输出根据任务而定，解码器输出就是下一个字的概率矩阵；
- 编码器通过MLM（随机掩码学习）NSP（下一句预测）等方式训练，解码器训练下一个字的预测和生成；
- 编码器的训练方法与推理场景不完全匹配、导致参数不合适；
- 编码器吸收多，输出少；
- 解码器更基本；
- 大参数、大算力、大数据支持；

### 自注意力溯源
- 神经网络
  - 深度神经网络
    - CNN（卷积神经网络）
    - RNN（循环神经网络）
      - LSTM、CRU
      - StoS 序列到序列模型
        - 编码器+解码器
    - 注意力机制
      - Transformer
        - 纯编码器（双向自注意力）
        - 纯解码器（单向自注意力）


### 大模型的可解释性？
#### 人类思考的三种模式
- 逻辑思考/推理
  - 演绎
  - 归纳
- 概率/统计
 - 相关
- 直觉

#### 人工智能的两种范式
- 符号主义？（形式逻辑）
	- 预先设定的规则
	- 确定的、可解释的
- 连接主义？（神经网络）
	- 自主学习到的参数（规则、逻辑）
	- 随机的、不可解释的

#### 大模型的随机性
- 推理
  - 输出层（随机确定下一个token）
    - > 好处：多样性、鲁棒性、有助于创意式生成
    - > 坏处：没有 确定性/准确性、幂等性、可管理性，不利于创意式生成
- 训练
  - 参数随机初始化
  - 随机打乱训练数据/随机梯度下降
  - Dropout（随机关闭神经元）

#### 大模型的参数不可解读性
- 结构无区别
- 随机初始化
- 数据量大（参数）
- 无法参照现有人类知识体系解读

好处：智能？

坏处：难以管理、压缩、裁剪、定向加强/减弱


### 未来
- 插件
  - 计算
  - 搜索
  - 代码
- 多模态
- 参数规模
- 多模型
  - MoE
- 推训一体（长期记忆）
- 分布式
- 个性化

